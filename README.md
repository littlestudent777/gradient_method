# Градиентный метод
Лабораторная работа по курсу "Методы оптимизации", 6 семестр

## Постановка задачи
Требуется решить задачу безусловной минимизации нелинейной функции (отличной от квадратичной) градиентными методами.  
Рассматривается следующая функция:
$$f(x,y) = \frac{1}{2}x^2 + \frac{1}{2}y^2 + \sin^2(x)\cos^2(y)$$

## Методы решения
1. **Градиентный метод первого порядка (наискорейший спуск)**  
   - Подобрать параметры метода в соответствии с теоремой о сходимости.  
   - Подобрать метод одномерной минимизации (шаговый параметр), обеспечивая согласованность с внешним методом.  
   - Провести вычислительный эксперимент, подтверждающий ортогональность звеньев ломаной на двух последовательных итерациях.
     $$\langle \nabla f(x_k), \nabla f(x_{k+1}) \rangle \approx 0$$

2. **Градиентный метод второго порядка с выбором шага по принципу дробления (метод Пшеничного)**  
   - Реализовать метод и сравнить его эффективность с наискорейшим спуском.  

3. **Собственный метод первого порядка**  
   - Разработать модификацию градиентного метода первого порядка, которая работает не хуже наискорейшего спуска для конкретной функции.

## Выбор собственного метода
В коде - bottom_search_method :sunglasses:
### Градиентный метод с адаптивной матрицей

Итерационная схема метода:

$$D = \text{diag}\left( \frac{1}{1 + 2 \cos^2(x_2)}, \frac{1}{1 + 2 \sin^2(x_1)} \right)$$

$$x_{k+1} = x_k - \alpha_k D \nabla f(x_k)$$

#### Обоснование эффективности:

**Аппроксимация гессиана**  
Матрица $$D$$ аппроксимирует обратный гессиан в области минимума $$( x_1 \approx 0, x_2 \approx 0 $$):

$$D \approx \text{diag}(H^{-1})$$
Таким образом, метод становится похож на метод второго порядка, что обеспечивает быструю сходимость.

**Свойства матрицы $$D$$**:

- **Улучшенная обусловленность**  
  Для $$D = \text{diag}(d_1, d_2) $$ число обусловленности в спектральной норме:
  $$\kappa(D) = \frac{\max\{|d_1|, |d_2|\}}{\min\{|d_1|, |d_2|\}}.$$
  
  Оценки для диагональных элементов:
  - Для \( d_1 \):
    
    $$\cos^2(x_2) \in [0, 1] \implies d_1 \in \left[\frac{1}{3}, 1\right].$$
  - Для \( d_2 \):

    $$\sin^2(x_1) \in [0, 1] \implies d_2 \in \left[\frac{1}{3}, 1\right].$$
  
  Максимальное число обусловленности:
  
  $$\kappa(D) \leq \frac{1}{\frac{1}{3}} = 3.$$

- **Подавление осцилляций**  
  Диагональные элементы $$D$$ компенсируют нелинейные члены $$\sin^2(x_1)\cos^2(x_2)$$.
